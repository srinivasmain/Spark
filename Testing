import unittest
from unittest.mock import patch, MagicMock
from your_module import write_df_in_assets  # Replace 'your_module' with the actual module name

class TestWriteDFInAssets(unittest.TestCase):

    @patch('builtins.print')
    @patch('your_module.sparkUtil.write_dataframe_to_db')
    def test_write_df_in_assets(self, mock_write_dataframe, mock_print):
        # Sample data
        data = [(1, "Name1", "Type1"), (2, "Name2", "Type2")]

        schema = ["ID", "Name", "Type"]

        # Creating a DataFrame
        df = self.spark.createDataFrame(data, schema=schema)

        # Calling the function
        write_df_in_assets(df, 'your_properties_file_name', 'your_table_name')

        # Assertions
        mock_print.assert_called_with("=======going to insert data in your_table_name========")

        # Additional assertions as needed
        mock_write_dataframe.assert_not_called()  # Since the actual writing is commented out

if __name__ == '__main__':
    unittest.main()
